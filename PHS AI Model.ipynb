{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install visualkeras\n",
    "!pip install pydot\n",
    "!sudo install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b24da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import visualkeras\n",
    "import os\n",
    "import itertools\n",
    "import tqdm\n",
    "import random\n",
    "from keras.preprocessing.image import load_img\n",
    "import PIL\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax, tanh\n",
    "from tensorflow.keras.layers import  Activation, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, MaxPool2D,Dropout, Add, AveragePooling2D\n",
    "from tensorflow.keras.metrics import Recall, Accuracy, Precision\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LearningRateScheduler,  ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = []\n",
    "label = []\n",
    "\n",
    "for cls in os.listdir(\"Data\"):\n",
    "  for path in os.listdir(os.path.join(\"Data\", cls)):\n",
    "    if cls == 'Normal':\n",
    "      label.append(0)\n",
    "    else:\n",
    "      label.append(1)\n",
    "    input_path.append(os.path.join(\"Data\", cls, path))\n",
    "  print(input_path[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label)\n",
    "len(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00703c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['images'] = input_path\n",
    "df['label'] = label\n",
    "df = df.sample(frac = 1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['images']:\n",
    "  if '.jpg' not in i:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc96622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['images'] != 'Data/HeatStress/Thumbs.db']\n",
    "df = df[df['images'] != 'Data/Normal/Thumbs.db']\n",
    "df = df[df['images'] != 'Data/HeatStress/11702.jpg']\n",
    "df = df[df['images'] != 'Data/Normal/666.jpg']\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "l = []\n",
    "\n",
    "for image in df['images']:\n",
    "  try:\n",
    "    img = PIL.Image.open(image)\n",
    "  except Exception as e:\n",
    "    l.append(image)\n",
    "\n",
    "l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==1]['images']\n",
    "start = random.randint(0, len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "  plt.subplot(5,5, index+1)\n",
    "  img = load_img(file)\n",
    "  img = np.array(img)\n",
    "  plt.imshow(img)\n",
    "  plt.title('HeatStress')\n",
    "  plt.axis('off')\n",
    "plt.savefig(\"HeatStress Figures.jpg\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf751b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==0]['images']\n",
    "start = random.randint(0, len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "  plt.subplot(5,5, index+1)\n",
    "  img = load_img(file)\n",
    "  img = np.array(img)\n",
    "  plt.imshow(img)\n",
    "  plt.title('Normal')\n",
    "  plt.axis('off')\n",
    "plt.savefig(\"Normal Figures.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7180a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dad903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_generator=ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_iterator = train_generator.flow_from_dataframe(\n",
    "    train, \n",
    "    x_col='images', \n",
    "    y_col='label', \n",
    "    target_size=(128,128), \n",
    "    batch_size=512, \n",
    "    class_mode='binary',\n",
    "    color_mode=\"grayscale\",\n",
    "    \n",
    "    )\n",
    "\n",
    "val_iterator = train_generator.flow_from_dataframe(\n",
    "    test, \n",
    "    x_col='images', \n",
    "    y_col='label', \n",
    "    target_size=(128,128), \n",
    "    batch_size=512, \n",
    "    class_mode='binary',\n",
    "    color_mode=\"grayscale\",\n",
    "    \n",
    "    )\n",
    "\n",
    "print(tf.shape(val_iterator.next()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mai_Net():\n",
    "    model = tf.keras.models.Sequential([\n",
    "                                        Conv2D(16, (2,2), activation='relu', input_shape=(128,128, 1)),\n",
    "                                        MaxPool2D((2,2)),\n",
    "                                        Conv2D(32, (2,2), activation='relu'),\n",
    "                                        MaxPool2D((2,2)),\n",
    "                                        Conv2D(64,(3,3), activation='relu'),\n",
    "                                        MaxPool2D((2,2)),\n",
    "                                        Flatten(),\n",
    "                                        Dense(512, activation='relu'),\n",
    "                                        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = mai_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee1424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "history = model.fit(train_iterator, epochs=10, validation_data=val_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf6fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc,'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc,'r', label='Validation Accuracy')\n",
    "plt.title('maiNetCNN - Accuracy Graph')\n",
    "plt.legend()\n",
    "plt.savefig(\"maiNetCNN - Accuracy Graph.jpg\")\n",
    "plt.figure()\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, loss,'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss,'r', label='Validation Validation Loss')\n",
    "plt.title('maiNetCNN - Loss Graph')\n",
    "plt.legend()\n",
    "plt.savefig(\"maiNetCNN - Loss Graph.jpg\")\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mai_Net2_dec24_96.4perc.h5')\n",
    "# model = tf.keras.models.load_model('mai_Net2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='Mai_Net_CNN.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f990336",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='mai_net CNN - visualized.png').show() # write and show\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe132c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[\"testNormal\", \"testHeatStress\"]\n",
    "targ = 0\n",
    "target = os.listdir(paths[targ])\n",
    "classes = [\"NormalDesu\", \"HeatStress\"]\n",
    "\n",
    "norms = 0\n",
    "heats = 0\n",
    "\n",
    "for img in target:\n",
    "    full_path = os.path.join(paths[targ],img )\n",
    "#     numpy image -> keras image tensor\n",
    "#     img = tf.keras.preprocessing.image.load_img(full_path, target_size=(128, 128), color_mode='grayscale')\n",
    "    img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_tensor /= 255. \n",
    "#     print(img_tensor.shape)\n",
    "    \n",
    "    res = model.predict(np.array(img_tensor).reshape(-1, 128, 128, 1))\n",
    "    sres = np.squeeze(res)\n",
    "    rsres = round(float(sres))\n",
    "    print(f\"{classes[rsres]} -> {full_path}\")\n",
    "    \n",
    "    if rsres == 0 : norms += 1\n",
    "    else : heats += 1\n",
    "        \n",
    "print(f\"Normal : {norms} - Heats : {heats}\")\n",
    "#     arged = np.argmax(res)\n",
    "#     result = classes[np.argmax(np.squeeze(res))]\n",
    "#     print(f\" Model Result -> {result}\")\n",
    "\n",
    "    \n",
    "# for img in normal:\n",
    "#     imgg = cv2.imread(os.path.join(\"testNormal\",img), cv2.IMREAD_GRAYSCALE)\n",
    "#     imgg = cv2.resize(imgg, (128, 128))/255.0\n",
    "#     res = model.predict(np.array(imgg).reshape(-1, 128, 128, 1))\n",
    "\n",
    "#     result = classes[np.argmax(np.squeeze(res))]\n",
    "# #     if res[0][0] > .50: result = \"HeatStress\"\n",
    "# #     else: result = \"Normal\"\n",
    "    \n",
    "#     print(f\"Totest -> {img}, Model Result -> {np.argmax(np.squeeze(res))}, Identification -> {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda769b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
